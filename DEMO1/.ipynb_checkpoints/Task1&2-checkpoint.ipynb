{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "\n",
    "d = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y: torch.exp(-(x**2+y**2)/2.0)\n",
    "\n",
    "X, Y = np.mgrid[-4.0:4:0.01,-4.0:4:0.01]\n",
    "\n",
    "x = torch.Tensor(X).to(d)\n",
    "y = torch.Tensor(Y).to(d)\n",
    "\n",
    "plt.imshow(f(x,y).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 AI Tasks\n",
    "\n",
    "I'll be using monkey_on_typewriter_gpt to get my answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random; monkey_on_typewriter_gpt = lambda prompt, N = 'still', keys = list(range(32, 125)) + [10,], actual_advice = '\\n\\nIf your question is related to numpy refer to the numpy docs at https://numpy.org/doc/\\nIf your question is related to pytorch refer to the pytorch docs at https://docs.pytorch.org/docs/stable/index.html',ego_stroking = ['Wow, what a thoughtful and insightful question, \\n\\n', 'This is an interesting quesiton, not many people would think to ask it, \\n\\n','You clearly already have a deep understanding, I will see what i can add, \\n\\n']: monkey_on_typewriter_gpt('', N = random.seed(prompt)) if N == 'still' else print(random.choice(ego_stroking), ''.join([chr(random.choice(keys)) for i in range(1, random.randint(1,1200))]),actual_advice, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_on_typewriter_gpt('Generate a Python script to plot a 2D Gaussian function using Numpy and Matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the monkey on the typewriter part was not super useful, but the references it listed are pretty helpful! I followed the links and then figured it out myself :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y: np.exp(-(x**2+y**2)/2.0)\n",
    "\n",
    "x,y = np.mgrid[-4.0:4:0.01,-4.0:4:0.01]\n",
    "\n",
    "plt.imshow(f(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I'll be using the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey_on_typewriter_gpt(\"Generate a Python script to plot a 2D Gaussian function using Pytorch and Matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then read through the pytorch docs and realised that this has already been implemented above! No work needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y: torch.sin(x+y)\n",
    "X, Y = np.mgrid[-4.0:4:0.01,-4.0:4:0.01]\n",
    "x,y = torch.Tensor(X).to(d), torch.Tensor(Y).to(d)\n",
    "plt.imshow(f(x,y).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,y: torch.sin(x+y)*torch.exp(-(x**2+y**2)/2.0)\n",
    "X, Y = np.mgrid[-4.0:4:0.01,-4.0:4:0.01]\n",
    "x,y = torch.Tensor(X).to(d), torch.Tensor(Y).to(d)\n",
    "plt.imshow(f(x,y).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from jpcf.base.frame_class import interactable_canvas\n",
    "from jpcf.extended.complex_class import cif as numpy_cif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_arange(start, stop, step):\n",
    "    return ((np.arange(0,step).astype(np.float64)/(step-1))) * (stop - start) + start\n",
    "\n",
    "class cif:\n",
    "    \"\"\"Complex Iterated Function class\n",
    "    \"\"\"\n",
    "    #AS PER https://stackoverflow.com/questions/16500656/which-color-gradient-is-used-to-color-mandelbrot-in-wikipedia#25816111\n",
    "    #I'm not super creative and i think the Wikipeia one looks clean :)\n",
    "    mapping = [\n",
    "    (66, 30, 15),(25, 7, 26),(9, 1, 47),\n",
    "    (4, 4, 73),(0, 7, 100),(12, 44, 138),\n",
    "    (24, 82, 177),(57, 125, 209),(134, 181, 229),\n",
    "    (211, 236, 248),(241, 233, 191),(248, 201, 95),\n",
    "    (255, 170, 0),(204, 128, 0),(153, 87, 0),\n",
    "    (106, 52, 3)\n",
    "    ]\n",
    "    map_arr = [\n",
    "        torch.Tensor(np.array([val[0] for val in mapping])).to(d),\n",
    "        torch.Tensor(np.array([val[1] for val in mapping])).to(d),\n",
    "        torch.Tensor(np.array([val[2] for val in mapping])).to(d)\n",
    "    ]\n",
    "\n",
    "    def __init__(self, f, width, height, Cutoff, count_factor = 1.0):\n",
    "\n",
    "        \"\"\"This class allows you to apply a transformation to a section of the complex plane, \n",
    "        every time you apply a batch of transormations it returns a numpy image representation of the\n",
    "        section.\n",
    "\n",
    "        Args:\n",
    "            f (lambda x, x0): A function that does some opation to two numpyarray with datatype 'complex'\n",
    "            width (int): The width of the image in px\n",
    "            height (int): The height of the image in px\n",
    "            Cutoff (float): The value in which if the arg of the number goes above, we note the iteration it occured on.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.f = f\n",
    "        self.width, self.height = width, height\n",
    "        self.Cutoff = Cutoff\n",
    "        self.count_factor = count_factor\n",
    "\n",
    "        self.M = None # The current matrix of values\n",
    "        self.M0 = None # The previous matrix of values\n",
    "        self.Count = None # The iteration the points arg became greater than Cutoff\n",
    "        self.Final = None # The point when the arg first became greater than Cutoff\n",
    "        \n",
    "        #NOTE: this is not exactly correct, for the sake of simplfication it is though ;)\n",
    "        self.Final_1 = None # The previous point when the arg first became greater than Cutoff\n",
    "\n",
    "        self.i = None\n",
    "\n",
    "\n",
    "    def start(self, x0,y0,x1,y1):\n",
    "        \"\"\"Initializes the internal variables.\n",
    "\n",
    "        Args:\n",
    "            x0 (float): The left xlim\n",
    "            y0 (float): The top ylim\n",
    "            x1 (float): The right xlim\n",
    "            y1 (float): The bottom ylim\n",
    "        \"\"\"\n",
    "        self.M = torch.tensor((np.array([strict_arange(x0, x1, self.width) for _ in range(self.height)]) + \\\n",
    "                np.transpose(np.array([strict_arange(y0,y1,self.height) for _ in range(self.width)])) * 1j).astype(np.complex64),\n",
    "                dtype=torch.cfloat).to(d)\n",
    "        self.M0 = torch.Tensor(self.M).to(d)\n",
    "        self.Count = torch.Tensor(np.zeros(self.M.shape).astype(np.int64)).to(d)\n",
    "        self.Final = torch.Tensor(np.zeros(self.M.shape).astype(np.float64)).to(d)\n",
    "        self.Final1 = torch.Tensor(np.zeros(self.M.shape).astype(np.float64)).to(d)\n",
    "        self.M1 = torch.Tensor(np.zeros(self.M.shape).astype(np.float64)).to(d)\n",
    "        self.i = torch.Tensor(np.zeros(self.M.shape).astype(np.int64)).to(d)\n",
    "\n",
    "    def val(self, Iterations):\n",
    "        \"\"\"Get the image of the state after Iterations.\n",
    "\n",
    "        Args:\n",
    "            Iterations (int): The number of iterations you wish to do.\n",
    "\n",
    "        Returns:\n",
    "            np.array(shape = (self.Width, self.Height, 3)).astype(int): The image representing the state of the sim.\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        for _ in range(Iterations):\n",
    "            self.i = self.i + 1\n",
    "            self.Count = self.Count + (self.Count == 0) * (torch.abs(self.M) > self.Cutoff) * self.i\n",
    "            self.Final = torch.where((self.Final == 0) & (torch.abs(self.M) > self.Cutoff), torch.abs(self.M), self.Final)\n",
    "            self.Final1 = torch.where((self.Final1 == 0) & (torch.abs(self.M) > self.Cutoff), \n",
    "                                ((self.Cutoff-torch.abs(self.M1))/(torch.abs(self.M) - torch.abs(self.M1))), \n",
    "                                self.Final1) #so here Final1 actually stores the \"decimal count\" its calcuated naively.\n",
    "            self.M1 = torch.Tensor(self.M).to(d)\n",
    "            self.M = self.f(self.M, self.M0)\n",
    "\n",
    "        return (torch.dstack([\n",
    "            cif.map_arr[2][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[1][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[0][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0)\n",
    "            ]) \n",
    "            +\n",
    "            (\n",
    "            torch.dstack([\n",
    "            cif.map_arr[2][(((self.Count+1)*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[1][(((self.Count+1)*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[0][(((self.Count+1)*self.count_factor) % 16).to(torch.int)] * (self.Count != 0)\n",
    "            ]) -    \n",
    "            torch.dstack([\n",
    "            cif.map_arr[2][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[1][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0),\n",
    "            cif.map_arr[0][((self.Count*self.count_factor) % 16).to(torch.int)] * (self.Count != 0)\n",
    "            ])\n",
    "            )\n",
    "            * torch.dstack([\n",
    "                self.Final1,\n",
    "                self.Final1,\n",
    "                self.Final1\n",
    "            ])\n",
    "        ).cpu().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 300\n",
    "HEIGHT = 300\n",
    "\n",
    "fn = cif(f = lambda x, x0: x*x+x0, width=WIDTH, height=HEIGHT, Cutoff=4, count_factor = 1.0)\n",
    "\n",
    "can = interactable_canvas(WIDTH,HEIGHT,fn,MAX_ITER=200,x0=-2,y0=-2,x1=2,y1=2)\n",
    "\n",
    "can.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
